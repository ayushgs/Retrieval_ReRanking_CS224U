{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "import math\n",
    "from math import log2\n",
    "import utils\n",
    "from collections import Counter, defaultdict\n",
    "import copy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_name = os.getcwd()\n",
    "data_dir_name = \"project_data\"\n",
    "data_dir = os.path.join(base_dir_name, data_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(signal_filename, relevance_filename, vocab_dict, vocab_id_list, vocab_frequency):\n",
    "    \n",
    "    # We will return these 7 things!\n",
    "    query_dict = {} #maps queries to query id (Assuming distinct queries)\n",
    "    doc_dict = {}  #maps docs to doc id\n",
    "    query_doc_dict = {} #maps query ids to list of doc ids\n",
    "    query_id_list = [] #list\n",
    "    doc_id_list = []\n",
    "    query_doc_relevance = {}\n",
    "    docId_to_content = {} #dict maps from doc id to the contents in the doc. The content is saved as a list of vocab_ids\n",
    "    results_dict = {\n",
    "        'query_dict': query_dict,\n",
    "        'doc_dict': doc_dict,\n",
    "        'query_doc_dict': query_doc_dict,\n",
    "        'query_id_list': query_id_list,\n",
    "        'doc_id_list': doc_id_list,\n",
    "        'query_doc_relevance': query_doc_relevance,\n",
    "        'docId_to_content': docId_to_content,\n",
    "    }\n",
    "    \n",
    "    doc_list_for_query = []\n",
    "    query_repetitions = {} #dict mapping queries to number of repetitions\n",
    "    query_counter = 0\n",
    "    doc_repetitions = 0\n",
    "\n",
    "    with open(os.path.join(data_dir, signal_filename), \"r\", encoding='utf8') as f:\n",
    "        last_query_id = 0 \n",
    "        for line in f:\n",
    "            line_list = line.split()\n",
    "            if line_list[0] == 'query:':\n",
    "                query_counter += 1\n",
    "                if query_counter >= 2:\n",
    "                    query_doc_dict[last_query_id] = doc_list_for_query\n",
    "\n",
    "                query = \" \".join(line_list[1:])\n",
    "\n",
    "                if query_dict.get(query, None) != None:\n",
    "                    query_repetitions[query] = query_repetitions.get(query, 0) + 1\n",
    "                    query = query + \"_\" + str(query_repetitions[query])\n",
    "\n",
    "                query_id_list.append(query)\n",
    "                query_dict[query] = len(query_id_list) - 1\n",
    "\n",
    "                last_query_id = len(query_id_list) - 1 #update the last query whenever a new query starts\n",
    "                doc_list_for_query = [] #reinitialize the doc list whenever a new query starts\n",
    "\n",
    "            elif line_list[0] == 'url:':\n",
    "                assert len(line_list) == 2, \"line_list for url has more than 2 entries. Please check!\"\n",
    "                doc = line_list[1]\n",
    "                if doc_dict.get(doc, None) == None:\n",
    "                    doc_id_list.append(doc)\n",
    "                    doc_id = len(doc_id_list) -1\n",
    "                    doc_dict[doc] = doc_id\n",
    "                else:\n",
    "                    doc_id = doc_dict[doc]\n",
    "                if doc_id not in doc_list_for_query: \n",
    "                    doc_list_for_query.append(doc_id)\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        query_doc_dict[last_query_id] = doc_list_for_query\n",
    "\n",
    "\n",
    "    query_total_repetitions = copy.deepcopy(query_repetitions)\n",
    "    doc_relevance_dict = {}\n",
    "    query_counter = 0\n",
    "    with open(os.path.join(data_dir, relevance_filename), \"r\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line_list = line.split()\n",
    "            if line_list[0] == 'query:':\n",
    "                query_counter += 1\n",
    "                query = \" \".join(line_list[1:])\n",
    "                if query_repetitions.get(query, None) != None:\n",
    "                    query_repetition_number = query_total_repetitions[query] - query_repetitions[query]\n",
    "                    query_repetitions[query] -= 1\n",
    "                    if query_repetition_number != 0:\n",
    "                        query = query + \"_\" + str(query_repetition_number)\n",
    "\n",
    "                if query_counter >= 2:\n",
    "                    assert query_doc_relevance.get(last_query_id, None) == None, \"Query already existed in the relevance dict\"\n",
    "                    query_doc_relevance[last_query_id] = doc_relevance_dict\n",
    "\n",
    "                last_query_id = query_dict[query]\n",
    "                doc_relevance_dict = {}\n",
    "\n",
    "            elif line_list[0] == \"url:\":\n",
    "                doc = line_list[1]\n",
    "                docID = doc_dict[doc]\n",
    "\n",
    "                doc_relevance_dict[docID] = float(line_list[-1].strip())\n",
    "\n",
    "        query_doc_relevance[last_query_id] = doc_relevance_dict\n",
    "        \n",
    "    #building word corpus for each document\n",
    "    doc_counter = 0\n",
    "    last_doc_content = defaultdict(list)\n",
    "\n",
    "    with open(os.path.join(data_dir, signal_filename), \"r\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line_list = line.split()\n",
    "\n",
    "            if line_list[0] == 'query:':\n",
    "                query = \" \".join(line_list[1:])\n",
    "                queryID = query_dict[query]\n",
    "                for word in line_list[1:]:\n",
    "                    word = word.strip().lower()\n",
    "                    vocab_frequency[word] = vocab_frequency.get(word, 0) + 1\n",
    "\n",
    "                    if vocab_dict.get(word, None) == None:\n",
    "                        vocab_id_list.append(word)\n",
    "                        vocab_dict[word] = len(vocab_id_list) - 1\n",
    "\n",
    "            elif line_list[0] == 'url:':\n",
    "                doc_counter += 1\n",
    "\n",
    "                doc = line_list[1]\n",
    "                docID = doc_dict[doc]\n",
    "\n",
    "                if doc_counter >= 2:\n",
    "                    docId_to_content[last_docID] = last_doc_content\n",
    "\n",
    "                last_doc_content = defaultdict(list)\n",
    "                last_docID = docID\n",
    "\n",
    "            elif line_list[0] == 'title:':\n",
    "                for word in line_list[1:]:\n",
    "                    word = word.strip().lower()\n",
    "                    vocab_frequency[word] = vocab_frequency.get(word, 0) + 1\n",
    "\n",
    "                    if vocab_dict.get(word, None) == None:\n",
    "                        vocab_id_list.append(word)\n",
    "                        vocab_dict[word] = len(vocab_id_list) - 1\n",
    "\n",
    "                    word_id = vocab_dict[word]\n",
    "                    last_doc_content['title'].append(word_id)\n",
    "\n",
    "            elif line_list[0] == 'header:':\n",
    "                for word in line_list[1:]:\n",
    "                    word = word.strip().lower()\n",
    "                    vocab_frequency[word] = vocab_frequency.get(word, 0) + 1\n",
    "\n",
    "                    if vocab_dict.get(word, None) == None:\n",
    "                        vocab_id_list.append(word)\n",
    "                        vocab_dict[word] = len(vocab_id_list) - 1\n",
    "\n",
    "                    word_id = vocab_dict[word]\n",
    "                    last_doc_content['header'].append(word_id)\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        docId_to_content[last_docID] = last_doc_content\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab includes words from both, query and docs\n",
    "vocab_dict = {} #mapping from vocab term to id \n",
    "vocab_id_list = [] #list where id maps to the vocab term (0 indexed)\n",
    "vocab_frequency = {} #number of times each vocab term appears in the vocab of documents (included query words)\n",
    "\n",
    "train_dict = load_data(\"pa3.signal.train\", \"pa3.rel.train\", vocab_dict, vocab_id_list, vocab_frequency)\n",
    "dev_dict = load_data(\"pa3.signal.dev\", \"pa3.rel.dev\", vocab_dict, vocab_id_list, vocab_frequency)\n",
    "pkl.dump(dev_dict['doc_id_list'], open('dev_doc_id_list.p', 'wb'))\n",
    "pkl.dump(dev_dict['doc_dict'], open('dev_doc_dict.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing query and document embeddings\n",
    "\n",
    "Document embeddings are obtained from the given title or header information without any weight normalization. Loop through the files and collect doc words by looking in the title and header (one idea can be to give more weight to title than to header). Lookup for each word in the glove embedding. Choose and fix a random combination of word if a word in query does not exist (maybe a combination from the words university and around because the corpus relates to stanford). Ignore otherwise. Finally, find cosine similarity and rank and compute NDCG score. \n",
    "\n",
    "#### Other ideas:\n",
    "1. Treat upper case and start of line word different than end of line word, etc\n",
    "2. Can add word correction, etc\n",
    "3. How scraping documents and adding more words to document effect performance\n",
    "4. Modeling item-item dependency by seq2slate architecture\n",
    "5. Creating embedding for words in the query but not in the embedding vocab as a distinct combination for \n",
    "6. Training word2vec on this and then trying different ideas with the center and context matrices obtained\n",
    "7. DESM type ideas with the embeddings of words in the document weighted by the similarity of words (W_out * q_emb)\n",
    "8. Treating re-ranking task as an NLI task where document entails query\n",
    "9. regressing score for each query-doc pair using nlp inspired regression by predicting score through RNN for instance\n",
    "10. experimenting with listwise and pairwise approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstracting away data structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data structures we need:\n",
    "    query_dict = {} #maps queries to query id (Assuming distinct queries)\n",
    "    query_id_list = [] #list of queries\n",
    "\n",
    "    doc_dict = {}  #maps urls to doc id\n",
    "    doc_id_list = [] # list of urls\n",
    "\n",
    "    query_doc_dict = {} #maps query ids to list of doc ids\n",
    "    \n",
    "    docId_to_content = {} #dict maps from doc id to the contents in the doc. The content is saved as a list of vocab_ids\n",
    "\n",
    "    #vocab includes words from both, query and docs\n",
    "    vocab_dict = {} #mapping from vocab term to id \n",
    "    vocab_id_list = [] #list where id maps to the vocab term (0 indexed)\n",
    "    vocab_frequency = {} \n",
    "\"\"\"   \n",
    "# dataset_dict is an argument to most of these, \n",
    "# as we need to know if we are dealing with train set, dev set\n",
    "def get_query_string(dataset_dict, query):\n",
    "    if type(query) == int:\n",
    "        query = dataset_dict['query_id_list'][query]\n",
    "    assert type(query) == str, query\n",
    "    return query\n",
    "\n",
    "def get_query_id(dataset_dict, query):\n",
    "    if type(query) == str:\n",
    "        query = dataset_dict['query_dict'][query]\n",
    "    assert type(query) == int, query\n",
    "    return query\n",
    " \n",
    "def get_doc_url(dataset_dict, doc):\n",
    "    if type(doc) == int:\n",
    "        doc = dataset_dict['doc_id_list'][doc]\n",
    "    assert type(doc) == str, doc\n",
    "    return doc\n",
    "\n",
    "def get_doc_id(dataset_dict, doc):\n",
    "    if type(doc) == str:\n",
    "        doc = dataset_dict['doc_dict'][doc]\n",
    "    assert type(doc) == int, doc\n",
    "    return doc\n",
    "\n",
    "# this should be common to everything across train/dev\n",
    "def ids_to_words(content):\n",
    "    # convert ids to words\n",
    "    return [vocab_id_list[i] if type(i) == int else i for i in content]\n",
    "    #return [vocab_id_list[i] for i in content]\n",
    "\n",
    "# this should be common to everything across train/dev\n",
    "def words_to_ids(words):\n",
    "    return [vocab_dict[w] if type(w) == str else w for w in words]\n",
    "    #return [vocab_dict[w] for w in words]\n",
    "\n",
    "# this should be common to everything across train/dev\n",
    "def register_words(words):\n",
    "    for word in words:\n",
    "        if word not in vocab_dict:\n",
    "            vocab_dict[word] = len(vocab_id_list)\n",
    "            vocab_id_list.append(word)\n",
    "\n",
    "def get_query_words(dataset_dict, query):\n",
    "    # return a list of words corresponding to the query (either string query or query_id)\n",
    "    query = get_query_string(dataset_dict, query)\n",
    "    return query.split('_')[0].split(' ')\n",
    "    \n",
    "def get_doc_words(dataset_dict, document, content_type):\n",
    "    # given either url or doc_id\n",
    "    document = get_doc_id(dataset_dict, document)\n",
    "    # all documents have a title at least\n",
    "    doc_to_content = dataset_dict['docId_to_content']\n",
    "    title_content = doc_to_content[document]['title']\n",
    "    \n",
    "    if content_type == 'title':\n",
    "        content = title_content\n",
    "    \n",
    "    elif content_type == 'header':\n",
    "        if doc_to_content[document]['header']:\n",
    "            content = doc_to_content[document]['header']\n",
    "        else:\n",
    "            content = title_content\n",
    "    \n",
    "    elif content_type == '2th':\n",
    "        content = 2*title_content\n",
    "        content += doc_to_content[document]['header']\n",
    "    \n",
    "    elif content_type == 'body':\n",
    "        if doc_to_content[document]['body']:\n",
    "            content = doc_to_content[document]['body']\n",
    "        else:\n",
    "            content = title_content\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Invalid content type: {}\".format(content_type))\n",
    "\n",
    "    return ids_to_words(content)\n",
    "\n",
    "def get_all_doc_words(dataset_dict, query, content_type):\n",
    "    # return tuples of (url, content) corresponding \n",
    "    query = get_query_id(dataset_dict, query)\n",
    "    query_doc_dict = dataset_dict['query_doc_dict']\n",
    "    documents = [get_doc_url(dataset_dict, doc) for doc in query_doc_dict[query]]\n",
    "    return [(doc, get_doc_words(dataset_dict, doc, content_type)) for doc in documents]\n",
    "\n",
    "def get_relevance_dict(dataset_dict, query):\n",
    "    query = get_query_id(dataset_dict, query)\n",
    "    query_doc_relevance = dataset_dict['query_doc_relevance']\n",
    "    return {get_doc_url(dataset_dict, k): v for k, v in query_doc_relevance[query].items()}\n",
    "\n",
    "def query_iter(dataset_dict):\n",
    "    query_dict = dataset_dict['query_dict']\n",
    "    for query in query_dict:\n",
    "        yield query\n",
    "\n",
    "def url_iter(dataset_dict, query):\n",
    "    query_doc_dict = dataset_dict['query_doc_dict']\n",
    "    query = get_query_id(dataset_dict, query)\n",
    "\n",
    "    for doc in query_doc_dict[query]:\n",
    "        yield get_doc_url(dataset_dict, doc)\n",
    "        \n",
    "# Note: from here on out, you NEVER have to touch a datastructure, just use the functions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inject the body content (by url) into docId_to_content when available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionary\n",
      "Loading dictionary\n"
     ]
    }
   ],
   "source": [
    "def make_url_to_body(s=\"train\"):\n",
    "    name = \"{}_web_url_to_body.p\".format(s)\n",
    "    if not os.path.exists(name):\n",
    "        print(\"Making dictionary\")\n",
    "        web_vocab_id_list = pkl.load(open('{}_vocab_id_list.p'.format(s), 'rb'))\n",
    "        web_vocab_dict = pkl.load(open('{}_vocab_dict.p'.format(s), 'rb'))\n",
    "        web_docId_to_content = pkl.load(open('{}_doc_id_content.p'.format(s), 'rb'))\n",
    "        web_doc_id_list = pkl.load(open(\"{}_doc_id_list.p\".format(s), \"rb\"))\n",
    "        web_doc_dict = pkl.load(open(\"{}_doc_dict.p\".format(s), \"rb\"))\n",
    "        web_url_to_words = {}\n",
    "\n",
    "        for url, doc in web_doc_dict.items():\n",
    "            body_content = []\n",
    "            if doc in web_docId_to_content:\n",
    "                _, body_content = web_docId_to_content[doc]\n",
    "\n",
    "            body_content = [web_vocab_id_list[w] for w in body_content]\n",
    "            web_url_to_words[url] = body_content\n",
    "\n",
    "        pkl.dump(web_url_to_words, open(name, \"wb\"))\n",
    "\n",
    "    else:\n",
    "        print(\"Loading dictionary\")\n",
    "        web_url_to_words = pkl.load(open(name, \"rb\"))\n",
    "    return web_url_to_words\n",
    "\n",
    "train_web_url_to_words = make_url_to_body('train')\n",
    "dev_web_url_to_words = make_url_to_body('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201, 0)\n",
      "(1187, 0)\n"
     ]
    }
   ],
   "source": [
    "def fill_in(dataset_dict, web_url_to_words):\n",
    "    present, missing = 0, 0\n",
    "    for query in query_iter(dataset_dict):\n",
    "        for url in url_iter(dataset_dict, query):\n",
    "            if url in web_url_to_words:\n",
    "                content = web_url_to_words[url]\n",
    "                doc_id = get_doc_id(dataset_dict, url)\n",
    "                register_words(content)\n",
    "                content = words_to_ids(content)\n",
    "                docId_to_content = dataset_dict['docId_to_content']\n",
    "                docId_to_content[doc_id]['body'] = content\n",
    "                present += 1\n",
    "            else:\n",
    "                missing += 1\n",
    "    return present, missing\n",
    "\n",
    "print(fill_in(train_dict, train_web_url_to_words))\n",
    "print(fill_in(dev_dict, dev_web_url_to_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some sanity checks\n",
    "for query in query_iter(train_dict):\n",
    "    print(get_query_words(train_dict, query))\n",
    "    print()\n",
    "    print(get_all_doc_words(train_dict, query, 'title'))\n",
    "    print()\n",
    "    print(get_relevance_dict(train_dict, query))\n",
    "    print()\n",
    "    for url in url_iter(train_dict, query):\n",
    "        print(url)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in query_iter(dev_dict):\n",
    "    print(get_query_words(dev_dict, query))\n",
    "    print()\n",
    "    print(get_all_doc_words(dev_dict, query, 'title'))\n",
    "    print()\n",
    "    print(get_relevance_dict(dev_dict, query))\n",
    "    print()\n",
    "    for url in url_iter(dev_dict, query):\n",
    "        print(url)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''having generated query content and doc content, lets try ranking by cosine similarity between query and document \n",
    "embedding\n",
    "'''\n",
    "#iteration 1: ignore words not there in the embedding\n",
    "\n",
    "#lookup function\n",
    "GLOVE_HOME = os.path.join(base_dir_name, os.path.join('data', 'glove.6B'))\n",
    "glove_lookup = utils.glove2dict(os.path.join(GLOVE_HOME, 'glove.6B.100d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_glove_embedding(words, combine_func=None, glove_dim = 100):\n",
    "    for word in words:\n",
    "        assert isinstance(word, str), (type(word), word)\n",
    "    \n",
    "\n",
    "    all_vecs = np.array([glove_lookup[w] for w in words if w in glove_lookup]) \n",
    "\n",
    "    if len(all_vecs) == 0:\n",
    "        feats = np.zeros(glove_dim)    \n",
    "    else:       \n",
    "        if combine_func:\n",
    "            feats = combine_func(all_vecs)\n",
    "        else: # take the elemnetwise mean by default\n",
    "            feats = np.mean(all_vecs, axis=0) \n",
    "    return feats\n",
    "\n",
    "def query_and_document_embeddings(dataset_dict, query, query_combine_func=None, doc_combine_func=None, content_type='title'):\n",
    "    \"\"\"\n",
    "    query: Either query text, or id\n",
    "    query_combine_func: How to combine query GloVe embeddings (default is mean)\n",
    "    doc_combine_func: How to combine document GloVe embeddings (default is mean)\n",
    "    doc_content_type: How to select document content. TODO: make this do something\n",
    "    \"\"\"\n",
    "    query_words = get_query_words(dataset_dict, query)\n",
    "    query_embedding = make_glove_embedding(query_words, query_combine_func)\n",
    "        \n",
    "    document_embeddings = [(url, make_glove_embedding(words, doc_combine_func)) \n",
    "                               for url, words in get_all_doc_words(dataset_dict, query, content_type)]\n",
    "    return query_embedding, document_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric - NDCG, MAP\n",
    "\n",
    "can also incorporate Precision, MAP, etc. after binary conversion with decay rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCG(ranked_docs, relevance_dict):\n",
    "    '''This function takes an ordered/ranked document list with the ground truth relevance labels from the \n",
    "    relevance_dict and returns a DCG score for the retrieval/ranking.\n",
    "    Input -- \n",
    "        ranked_docs = list of doc IDs ordered by rank. First element in the list is the highest ranked\n",
    "        relevance_dict = dict with keys as the doc_IDs and relevance score as the element\n",
    "    Output -- \n",
    "        DCG [float]'''\n",
    "    return np.sum([(relevance_dict[doc]) / (math.log2(i+2)) \\\n",
    "                  for i, doc in enumerate(ranked_docs)])\n",
    "\n",
    "def DCG_alt(ranked_docs, relevance_dict):\n",
    "    return np.sum([(2**relevance_dict[doc] - 1) / (math.log2(i+2)) \\\n",
    "                   for i, doc in enumerate(ranked_docs)])\n",
    "\n",
    "def NDCG(ranked_docs, relevance_dict, use_alt=False):\n",
    "    '''This function takes an ordered/ranked document list with the ground truth relevance labels from the \n",
    "    relevance_dict and returns a NDCG score for the ranking. \n",
    "    Input -- \n",
    "        ranked_docs = list of doc IDs ordered by rank. First element in the list is the highest ranked\n",
    "        relevance_dict = dict with keys as the doc_IDs and relevance score as the element\n",
    "    Output -- \n",
    "        NDCG [float]'''\n",
    "    assert len(ranked_docs) == len(relevance_dict)\n",
    "    ideal_ordering, _ = zip(*sorted(relevance_dict.items(), key = lambda x: (-x[1])))\n",
    "    ideal_ordering = list(ideal_ordering)\n",
    "    \n",
    "    dcg_func = DCG_alt if use_alt else DCG\n",
    "    DCG_oracle = dcg_func(ideal_ordering, relevance_dict)\n",
    "    DCG_case = dcg_func(ranked_docs, relevance_dict)\n",
    "    assert DCG_oracle >= DCG_case\n",
    "    \n",
    "    #return 0 if DCG_ideal is 0 (happens when all the retrieved docs are rated 0)\n",
    "    if DCG_oracle == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return DCG_case/DCG_oracle\n",
    "\n",
    "#sanity check\n",
    "ranked_docs = [0,1,2,3,4]\n",
    "relevance_dict = {0: 2, 1: 3, 2: 0, 3: 0, 4: 1}\n",
    "DCG_score = 2 + 3/log2(3) + 1/log2(6)\n",
    "Ideal_score = 3 + 2/log2(3) + 1/log2(4)\n",
    "NDCG_score = DCG_score/Ideal_score\n",
    "assert DCG(ranked_docs, relevance_dict) == DCG_score, \"DCG error\"\n",
    "assert NDCG(ranked_docs, relevance_dict) == NDCG_score, \"NDCG error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_helper(relevance_list):\n",
    "    precision = 0.0\n",
    "    relevant_so_far = 0.0\n",
    "    for i, val in enumerate(relevance_list):\n",
    "        relevant_so_far += val\n",
    "        precision += relevant_so_far / (i+1)\n",
    "    return precision / len(relevance_list)\n",
    "\n",
    "def average_precision(ranked_doc_list, query_relevance_dict):\n",
    "    relevance_list = [1 if query_relevance_dict[doc] >= 1.0 else 0 for doc in ranked_doc_list]\n",
    "    return average_precision_helper(relevance_list)\n",
    "\n",
    "expected = (1 + 1 + 2/3 + 2/4 + 3/5 + 3/6 + 4/7)/ 7\n",
    "actual = average_precision_helper([1, 1, 0, 0, 1, 0, 1])\n",
    "assert expected == actual, actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_similarity(doc_embedding, query_embedding):\n",
    "    return np.random.uniform()\n",
    "\n",
    "def cosine_similarity(doc_embedding, query_embedding):\n",
    "    norm = np.linalg.norm(doc_embedding)\n",
    "    if norm > 0:\n",
    "        doc_embedding /= norm\n",
    "    \n",
    "    assert not np.any(doc_embedding == np.nan), \"doc embedding has nan {}\".format(doc_embedding)\n",
    "    assert not np.any(query_embedding == np.nan), \"query embedding has nan {}\".format(query_embedding)\n",
    "    \n",
    "    result = np.dot(doc_embedding, query_embedding)\n",
    "    \n",
    "    assert not np.any(result == np.nan), \"result has nan {}\".format(result)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_metrics(dataset_dict, scoring_func=cosine_similarity, content_type='title'):\n",
    "    ndcg_sum = 0.0\n",
    "    alt_ndcg_sum = 0.0\n",
    "    precision_sum = 0.0\n",
    "    n = 0\n",
    "    for query in query_iter(dataset_dict):\n",
    "        n += 1\n",
    "        query_relevance_dict = get_relevance_dict(dataset_dict, query)\n",
    "        query_embedding, document_embeddings = query_and_document_embeddings(dataset_dict, query, content_type=content_type)\n",
    "        \n",
    "        scores = [(url, scoring_func(doc_emb, query_embedding)) for url, doc_emb in document_embeddings]\n",
    "        scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "        ranked_doc_list, _ = zip(*scores)\n",
    "        ranked_doc_list = list(ranked_doc_list)\n",
    "\n",
    "        ndcg_sum += NDCG(ranked_doc_list, query_relevance_dict)\n",
    "        alt_ndcg_sum += NDCG(ranked_doc_list, query_relevance_dict, use_alt=True)\n",
    "        precision_sum += average_precision(ranked_doc_list, query_relevance_dict)\n",
    "        \n",
    "    ndcg_sum /= n\n",
    "    alt_ndcg_sum  /= n\n",
    "    precision_sum /= n\n",
    "    return {'NDCG': ndcg_sum,\n",
    "            'Alt_NDCG': alt_ndcg_sum,\n",
    "            'MAP': precision_sum,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random ordering accuracy\n",
    "\n",
    "For every query, arrange the docs in random order and check the NDCG value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random on train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8093945822887159,\n",
       " 'Alt_NDCG': 0.7412051889174038,\n",
       " 'MAP': 0.7266901783632905}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "sum_metric = {}\n",
    "for _ in range(n):\n",
    "    for m, v in run_metrics(train_dict, scoring_func=random_similarity).items():\n",
    "        sum_metric[m] = sum_metric.get(m, 0) + v / n\n",
    "print(\"Random on train\")\n",
    "sum_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random on dev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.809594350659827,\n",
       " 'Alt_NDCG': 0.7381466655511866,\n",
       " 'MAP': 0.7240766060456441}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "sum_metric = {}\n",
    "for _ in range(n):\n",
    "    for m, v in run_metrics(dev_dict, scoring_func=random_similarity).items():\n",
    "        sum_metric[m] = sum_metric.get(m, 0) + v / n\n",
    "print(\"Random on dev\")\n",
    "sum_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some non-random methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Title on train\")\n",
    "run_metrics(train_dict, scoring_func=cosine_similarity, content_type='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title on dev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8610811796421569,\n",
       " 'Alt_NDCG': 0.8111389290875022,\n",
       " 'MAP': 0.7623313263477439}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Title on dev\")\n",
    "run_metrics(dev_dict, scoring_func=cosine_similarity, content_type='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header on train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8568503022704564,\n",
       " 'Alt_NDCG': 0.8042551360163497,\n",
       " 'MAP': 0.7661671476556811}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Header on train\")\n",
    "run_metrics(train_dict, scoring_func=cosine_similarity, content_type='header')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header on dev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8595995880298966,\n",
       " 'Alt_NDCG': 0.8048907651704151,\n",
       " 'MAP': 0.7704660869724235}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Header on dev\")\n",
    "run_metrics(dev_dict, scoring_func=cosine_similarity, content_type='header')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*Title+header on train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8685425184105349,\n",
       " 'Alt_NDCG': 0.8196390620542968,\n",
       " 'MAP': 0.778713179048508}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2*Title+header on train\")\n",
    "run_metrics(train_dict, scoring_func=cosine_similarity, content_type='2th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*Title+header on dev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8702515039354958,\n",
       " 'Alt_NDCG': 0.8221430739588372,\n",
       " 'MAP': 0.776288219588911}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2*Title+header on dev\")\n",
    "run_metrics(dev_dict, scoring_func=cosine_similarity, content_type='2th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body on train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8538332875849136,\n",
       " 'Alt_NDCG': 0.7968008388330325,\n",
       " 'MAP': 0.7690100740266438}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Body on train\")\n",
    "run_metrics(train_dict, scoring_func=cosine_similarity, content_type='body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body on dev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8706960262890675,\n",
       " 'Alt_NDCG': 0.8121585630178958,\n",
       " 'MAP': 0.7961876798210322}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Body on dev\")\n",
    "run_metrics(dev_dict, scoring_func=cosine_similarity, content_type='body')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_concat_featurizer_base(dataset_dict, query, url, content_type):\n",
    "    \"\"\"\n",
    "        make an embedding for the query and url by concatenating their average glove vectors\n",
    "    \"\"\"\n",
    "    combine_func = lambda docs: np.mean(docs, axis=0)\n",
    "\n",
    "    query_words = get_query_words(dataset_dict, query)\n",
    "    query_embedding = make_glove_embedding(query_words, combine_func)\n",
    "    \n",
    "    doc_words = get_doc_words(dataset_dict, url, content_type)\n",
    "    document_embedding = make_glove_embedding(doc_words, combine_func) \n",
    "\n",
    "    return np.concatenate([query_embedding, document_embedding])\n",
    "\n",
    "def glove_concat_featurizer_title(dataset_dict, query, url):\n",
    "    return glove_concat_featurizer_base(dataset_dict, query, url, 'title')\n",
    "\n",
    "def glove_concat_featurizer_header(dataset_dict, query, url):\n",
    "    return glove_concat_featurizer_base(dataset_dict, query, url, 'header')\n",
    "\n",
    "def glove_concat_featurizer_body(dataset_dict, query, url):\n",
    "    return glove_concat_featurizer_base(dataset_dict, query, url, 'body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regression_dataset(dataset_dict, featurizer):\n",
    "    \"\"\"\n",
    "        dataset_dict: returned by load_data\n",
    "        featurizer: function that takes in (query, doc_content) pair and returns a featurization\n",
    "        \n",
    "        makes a dataset of (vector, relevance) pair where vector is made by the featurizer\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for query in query_iter(dataset_dict): \n",
    "        relevances = get_relevance_dict(dataset_dict, query)\n",
    "        for url in url_iter(dataset_dict, query):\n",
    "            embedding = featurizer(dataset_dict, query, url)\n",
    "            X.append(embedding)\n",
    "            y.append(relevances[url])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_metrics_ml(dataset_dict, ml_model, featurizer):\n",
    "    \"\"\"\n",
    "        dataset_dict: the dictionary returned by load_data\n",
    "        ml_model: a model that takes in X and outputs y predictions\n",
    "        featurizer: the featurizer function that feeds (query, document) \n",
    "            pairs to a format the ml_model can accept\n",
    "    \"\"\"\n",
    "    # TODO: shouldnt have to use the featurizer here, need to improve this API\n",
    "    ndcg_sum = 0.0\n",
    "    alt_ndcg_sum = 0.0\n",
    "    precision_sum = 0.0\n",
    "    n = 0\n",
    "    for query in query_iter(dataset_dict):\n",
    "        n += 1\n",
    "        query_relevance_dict = get_relevance_dict(dataset_dict, query)\n",
    "        \n",
    "        to_rank = [(url, featurizer(dataset_dict, query, url)) for url in url_iter(dataset_dict, query)]\n",
    "        vectors = [vector for _, vector in to_rank]\n",
    "        predictions = ml_model.predict(vectors)\n",
    "        scores = [(url, predictions[i]) for i, (url, _) in enumerate(to_rank)]\n",
    "        \n",
    "        scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "        ranked_doc_list, _ = zip(*scores)\n",
    "        ranked_doc_list = list(ranked_doc_list)\n",
    "\n",
    "        ndcg_sum += NDCG(ranked_doc_list, query_relevance_dict)\n",
    "        alt_ndcg_sum += NDCG(ranked_doc_list, query_relevance_dict, use_alt=True)\n",
    "        precision_sum += average_precision(ranked_doc_list, query_relevance_dict)\n",
    "    \n",
    "    ndcg_sum /= n\n",
    "    alt_ndcg_sum  /= n\n",
    "    precision_sum /= n\n",
    "    return {'NDCG': ndcg_sum,\n",
    "            'Alt_NDCG': alt_ndcg_sum,\n",
    "            'MAP': precision_sum,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_title = make_regression_dataset(train_dict, glove_concat_featurizer_title)\n",
    "training_dataset_header = make_regression_dataset(train_dict, glove_concat_featurizer_header)\n",
    "training_dataset_body = make_regression_dataset(train_dict, glove_concat_featurizer_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg:\n",
    "    def __init__(self):\n",
    "        self.model = LinearRegression()\n",
    "        \n",
    "    def train(self, dataset):\n",
    "        X, y = dataset\n",
    "        self.model = self.model.fit(X, y)\n",
    "        return self.model.score(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with title GloVe embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8542825508514621,\n",
       " 'Alt_NDCG': 0.7973529372338085,\n",
       " 'MAP': 0.7603503995684292}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression with title GloVe embeddings\")\n",
    "lin_reg = LinearReg()\n",
    "lin_reg.train(training_dataset_title)\n",
    "run_metrics_ml(dev_dict, lin_reg, glove_concat_featurizer_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with header GloVe embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8416788887548966,\n",
       " 'Alt_NDCG': 0.7794499958791133,\n",
       " 'MAP': 0.7566035997732421}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression with header GloVe embeddings\")\n",
    "lin_reg = LinearReg()\n",
    "lin_reg.train(training_dataset_header)\n",
    "run_metrics_ml(dev_dict, lin_reg, glove_concat_featurizer_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with body GloVe embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8258499182816925,\n",
       " 'Alt_NDCG': 0.7567527560828344,\n",
       " 'MAP': 0.7363864125399265}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression with body GloVe embeddings\")\n",
    "lin_reg = LinearReg()\n",
    "lin_reg.train(training_dataset_body)\n",
    "run_metrics_ml(dev_dict, lin_reg, glove_concat_featurizer_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetReg:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = MLPRegressor(**kwargs)\n",
    "        \n",
    "    def train(self, dataset):\n",
    "        X, y = dataset\n",
    "        self.model = self.model.fit(X, y)\n",
    "        return self.model.score(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two layer NN with title GloVe embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8579308707352411,\n",
       " 'Alt_NDCG': 0.8043217766965625,\n",
       " 'MAP': 0.7646668891570961}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Two layer NN with title GloVe embeddings\")\n",
    "nn_reg = NeuralNetReg(hidden_layer_sizes=(100,50), activation='relu', solver='adam')\n",
    "nn_reg.train(training_dataset_title)\n",
    "run_metrics_ml(dev_dict, nn_reg, glove_concat_featurizer_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two layer NN with header GloVe embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8491421579967309,\n",
       " 'Alt_NDCG': 0.7932276929762926,\n",
       " 'MAP': 0.7676799886621313}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Two layer NN with header GloVe embeddings\")\n",
    "nn_reg = NeuralNetReg(hidden_layer_sizes=(100,50), activation='relu', solver='adam')\n",
    "nn_reg.train(training_dataset_header)\n",
    "run_metrics_ml(dev_dict, nn_reg, glove_concat_featurizer_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two layer NN with body GloVe embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8521786615103065,\n",
       " 'Alt_NDCG': 0.7890672101783839,\n",
       " 'MAP': 0.7577567935776458}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Two layer NN with body GloVe embeddings\")\n",
    "nn_reg = NeuralNetReg(hidden_layer_sizes=(100,50), activation='relu', solver='adam')\n",
    "nn_reg.train(training_dataset_body)\n",
    "run_metrics_ml(dev_dict, nn_reg, glove_concat_featurizer_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(doc_embedding, query_embedding):\n",
    "    norm = np.linalg.norm(doc_embedding)\n",
    "    if norm > 0:\n",
    "        doc_embedding /= norm\n",
    "    return np.dot(doc_embedding, query_embedding)\n",
    "\n",
    "def similarity_featurizer(dataset_dict, query, url):\n",
    "    \"\"\"\n",
    "    featurizers a query document pair by creating a scalar cosine similarity value between the query embeddings \n",
    "    and document embeddings obtained by each content_type (title, headers, body). The idea is to use ML to find\n",
    "    the optimum weights for each of these similarities automatically to predict relevance scores\n",
    "    \"\"\"\n",
    "\n",
    "    query_words = get_query_words(dataset_dict, query)\n",
    "    query_embedding = make_glove_embedding(query_words)\n",
    "    \n",
    "    features = []\n",
    "    for content_type in [\"title\", \"header\", \"body\"]:\n",
    "        doc_words = get_doc_words(dataset_dict, url, content_type)\n",
    "        document_embedding = make_glove_embedding(doc_words) \n",
    "        features.append(cosine_similarity(document_embedding, query_embedding))\n",
    "        \n",
    "    return np.array(features)\n",
    "\n",
    "def similarity_featurizer_with2th(dataset_dict, query, url):\n",
    "    \"\"\"\n",
    "    featurizers a query document pair by creating a scalar cosine similarity value between the query embeddings \n",
    "    and document embeddings obtained by each content_type (title, headers, body). The idea is to use ML to find\n",
    "    the optimum weights for each of these similarities automatically to predict relevance scores\n",
    "    \"\"\"\n",
    "\n",
    "    query_words = get_query_words(dataset_dict, query)\n",
    "    query_embedding = make_glove_embedding(query_words)\n",
    "    \n",
    "    features = []\n",
    "    for content_type in [\"title\", \"header\", \"body\", \"2th\"]:\n",
    "        doc_words = get_doc_words(dataset_dict, url, content_type)\n",
    "        document_embedding = make_glove_embedding(doc_words) \n",
    "        features.append(cosine_similarity(query_embedding, document_embedding))\n",
    "        \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_similarity_regression_dataset(dataset_dict, featurizer):\n",
    "    \"\"\"\n",
    "        dataset_dict: returned by load_data\n",
    "        featurizer: function that takes in (query, doc_content) pair and returns a featurization\n",
    "        \n",
    "        makes a dataset of (vector, relevance) pair where vector is made by the featurizer\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for query in query_iter(dataset_dict): \n",
    "        relevances = get_relevance_dict(dataset_dict, query)\n",
    "        for url in url_iter(dataset_dict, query):\n",
    "            features = featurizer(dataset_dict, query, url)\n",
    "            X.append(features)\n",
    "            y.append(relevances[url])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_similarity = make_similarity_regression_dataset(train_dict, similarity_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8651824860113435,\n",
       " 'Alt_NDCG': 0.8161245513899243,\n",
       " 'MAP': 0.7771249238087184}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debugging the implementation\n",
    "class Debugging_Model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        result = [vector[0] for vector in X] \n",
    "        return result\n",
    "\n",
    "debugging_model = Debugging_Model()\n",
    "run_metrics_ml(train_dict, debugging_model, similarity_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression on Similarity Scores of each content type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8463247991376778,\n",
       " 'Alt_NDCG': 0.7903229998190744,\n",
       " 'MAP': 0.7503559999268529}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression on Similarity Scores of each content type\")\n",
    "lin_reg = LinearReg()\n",
    "lin_reg.train(training_dataset_similarity)\n",
    "run_metrics_ml(dev_dict, lin_reg, similarity_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two layer NN on Similarity Scores of each content type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8532155936549467,\n",
       " 'Alt_NDCG': 0.7992169291890753,\n",
       " 'MAP': 0.7562412832516521}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Two layer NN on Similarity Scores of each content type\")\n",
    "nn_reg = NeuralNetReg(hidden_layer_sizes=(100,50), activation='relu', solver='adam')\n",
    "nn_reg.train(training_dataset_similarity)\n",
    "run_metrics_ml(dev_dict, nn_reg, similarity_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_similarity_with2th = make_similarity_regression_dataset(train_dict, similarity_featurizer_with2th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression on Similarity Scores of each content type including 2th\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.848081434047984,\n",
       " 'Alt_NDCG': 0.7942189063825597,\n",
       " 'MAP': 0.7548713289079076}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression on Similarity Scores of each content type including 2th\")\n",
    "lin_reg = LinearReg()\n",
    "lin_reg.train(training_dataset_similarity_with2th)\n",
    "run_metrics_ml(dev_dict, lin_reg, similarity_featurizer_with2th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Two layer NN on Similarity Scores of each content type\")\n",
    "nn_reg = NeuralNetReg(hidden_layer_sizes=(100,50), activation='relu', solver='adam')\n",
    "nn_reg.train(training_dataset_similarity_with2th)\n",
    "run_metrics_ml(dev_dict, nn_reg, similarity_featurizer_with2th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Inspired extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class Word2Vec_IR(object):\n",
    "    '''trains word2vec inspired embedding for each title and header word in the relevant document\n",
    "    such that it is close to the query embedding. Through this, we hope to create entailment information'''\n",
    "    \n",
    "    def __init__(self, embed_dim = 100):\n",
    "        '''embed_dim:  same dimension as the glove embedding\n",
    "        Other class variables:\n",
    "            self.n_doc_words -- number of doc words in the vocab for which we create an embedding\n",
    "            self.n_data -- length of data (query, doc_word_id) tuples\n",
    "            self.W -- stores the doc embedding as |dim| x |vocab size|\n",
    "        '''\n",
    "        self.embed_dim = embed_dim\n",
    "        self.content_list = ['title', 'header']\n",
    "        self.stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    def make_word2vec_data(self, dataset_dict):\n",
    "        '''Creates the dataset required for word2vec training. For every query, it creates a list of tuples of \n",
    "        (query, doc_word_id)..., where doc_word are the words in the most relevant document for a given query \n",
    "        provided it has a relevance greater than equal to 1'''\n",
    "        self.data_list = []\n",
    "        self.id_to_word = [] # a list of doc words\n",
    "        self.word_to_id = {} # a dictionary mapping from a word to a id\n",
    "        \n",
    "        print('Creating dataset...')\n",
    "        for query in query_iter(dataset_dict):\n",
    "            query_relevance_dict = get_relevance_dict(dataset_dict, query)\n",
    "            query_words = get_query_words(dataset_dict, query)\n",
    "            query_embedding = make_glove_embedding(query_words)\n",
    "            \n",
    "            doc_url, rel = sorted(query_relevance_dict.items(), key = lambda x: -x[1])[0] #get the most relevant doc\n",
    "            if rel < 1:\n",
    "                continue\n",
    "            for content_type in self.content_list:\n",
    "                for doc_word in get_doc_words(dataset_dict, doc_url, content_type):\n",
    "                    if doc_word not in self.stop_words:\n",
    "                        if doc_word in self.word_to_id:\n",
    "                            doc_word_id = self.word_to_id[doc_word]\n",
    "                        else:\n",
    "                            self.id_to_word.append(doc_word)\n",
    "                            self.word_to_id[doc_word] = len(self.id_to_word) - 1\n",
    "                            doc_word_id = self.word_to_id[doc_word]\n",
    "                            \n",
    "                        self.data_list.append((query_embedding, doc_word_id))\n",
    "        \n",
    "        assert len(self.id_to_word) == len(self.word_to_id), \"length of words in word-id and id-word mapping is different\"\n",
    "        self.n_doc_words = len(self.id_to_word)\n",
    "        self.n_data = len(self.data_list)\n",
    "        \n",
    "        #converting the created data to tensor objects in x and y\n",
    "        x, y = zip(*self.data_list)\n",
    "        x, y = np.array(x), np.array(y)\n",
    "        x, y = torch.tensor(x, dtype = torch.float64), torch.tensor(y, dtype = torch.long)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        assert self.x.shape[0] == self.y.shape[0], \"x and y are of different lengths\"\n",
    "        print(\"Dataset making complete...\")\n",
    "        print(\"Total number of doc words = {}\".format(self.n_doc_words))\n",
    "        print(\"Length of dataset = {}\".format(self.n_data))\n",
    "        print(\"\\n\" + \"-\"*10 + \"\\n\")\n",
    "        \n",
    "                                \n",
    "    def train(self, max_iter = 100, learning_rate = 1e-2):\n",
    "        '''Function to train the word matrix for document that can carry entailment information. \n",
    "        Our hope is that a doc word that entails a set of queries finds its embedding closer to the query embeddings. \n",
    "        Since we have limited amount of data, embeddings of queries are kept fixed and we are only creating \n",
    "        and embedding lookup matrix of dimension - (vocab length of words) x dimension_size of embedding. '''\n",
    "        \n",
    "        W = torch.randn(self.n_doc_words, self.embed_dim, requires_grad = True)\n",
    "        tensor_data = TensorDataset(self.x, self.y)\n",
    "        loader = DataLoader(tensor_data, shuffle=True, batch_size=1)\n",
    "        self.loss_list = []\n",
    "        avg_loss = 0\n",
    "        #optimizer = torch.optim.Adam(W)\n",
    "        \n",
    "        print(\"Starting model training...\")\n",
    "        for t in range(1, max_iter + 1):\n",
    "            for x, y in loader:\n",
    "                x = torch.reshape(x, (-1,1))\n",
    "                z = W.mm(x.float())\n",
    "                output = F.log_softmax(z, dim = 0)\n",
    "                output = torch.reshape(output, (1,-1))\n",
    "                loss = F.nll_loss(output, y)\n",
    "                loss.backward()\n",
    "                \n",
    "                avg_loss += loss.item()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    W -= learning_rate * W.grad\n",
    "                    W.grad.zero_()\n",
    "                \n",
    "                #optimizer.step()\n",
    "                #optimizer.zero_grad()\n",
    "            avg_loss /= self.n_data\n",
    "            self.loss_list.append(avg_loss)\n",
    "            if t%10 == 0:\n",
    "                print(\"At iteration {}, loss = {}\".format(t, avg_loss))\n",
    "                \n",
    "        print(\"Training complete\")\n",
    "        self.W = torch.t(W)\n",
    "            \n",
    "    def plot_training_curve(self):\n",
    "        '''Plot the training curve at the end of training'''\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, len(self.loss_list) + 1), self.loss_list)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss Values\")\n",
    "        plt.title(\"Loss vs Iterations\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    def get_sim_score(self, dataset_dict, query_words, url):\n",
    "        '''Gives a similarity score between a query-document pair by finding the \n",
    "        doc product of query embedding (mean of glove for query words) with the document embedding ()'''\n",
    "        \n",
    "        query_embedding = make_glove_embedding(query_words)\n",
    "        document_words = get_doc_words(dataset_dict, url, content_type = '2th')\n",
    "        document_embedding = make_glove_embedding(document_words) \n",
    "        base_sim_score = cosine_similarity(document_embedding, query_embedding)\n",
    "        \n",
    "        embed_vectors_list = []\n",
    "        for doc_word in document_words:\n",
    "            if doc_word in self.word_to_id:\n",
    "                doc_word_id = self.word_to_id[doc_word]\n",
    "                hot_doc_vector = torch.zeros(self.n_doc_words,1).float()\n",
    "                hot_doc_vector[doc_word_id] = 1.0\n",
    "                doc_word_embedding = self.W.mm(hot_doc_vector)\n",
    "                doc_word_embedding = doc_word_embedding.detach().numpy().ravel() #now a numpy vector\n",
    "                embed_vectors_list.append(doc_word_embedding)\n",
    "        \n",
    "        if len(embed_vectors_list) == 0:\n",
    "            return base_sim_score\n",
    "        else:\n",
    "            doc_embed_word2vec = np.mean(np.array(embed_vectors_list), axis = 0)\n",
    "            word2vec_added_score = cosine_similarity(doc_embed_word2vec, query_embedding)\n",
    "            return base_sim_score + word2vec_added_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Dataset making complete...\n",
      "Total number of doc words = 2114\n",
      "Length of dataset = 11904\n",
      "\n",
      "----------\n",
      "\n",
      "Starting model training...\n",
      "At iteration 10, loss = 6.660933399187157\n",
      "At iteration 20, loss = 5.409551253088337\n",
      "At iteration 30, loss = 4.7149781685395\n",
      "At iteration 40, loss = 4.2720068550955155\n",
      "At iteration 50, loss = 3.97009020549953\n",
      "At iteration 60, loss = 3.748441603806919\n",
      "At iteration 70, loss = 3.5830311830615282\n",
      "At iteration 80, loss = 3.4544880558786195\n",
      "At iteration 90, loss = 3.353433049779915\n",
      "At iteration 100, loss = 3.2723865079061385\n",
      "Training complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word2vec_model = Word2Vec_IR()\n",
    "word2vec_model.make_word2vec_data(train_dict)\n",
    "word2vec_model.train()\n",
    "word2vec_model.plot_training_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_metrics_word2vec(dataset_dict, model = word2vec_model):\n",
    "    \"\"\"\n",
    "    Evaluates the word2vec inspired extended model on ndcg, ndcg alt, and map\n",
    "    content = 'th' because we built the word2vec embedding only for title and header word of documents\n",
    "    \"\"\"\n",
    "    # TODO: shouldnt have to use the featurizer here, need to improve this API\n",
    "    ndcg_sum = 0.0\n",
    "    alt_ndcg_sum = 0.0\n",
    "    precision_sum = 0.0\n",
    "    n = 0\n",
    "    \n",
    "    for query in query_iter(dataset_dict):\n",
    "        n += 1\n",
    "        query_relevance_dict = get_relevance_dict(dataset_dict, query)\n",
    "        query_words = get_query_words(dataset_dict, query)\n",
    "        \n",
    "        scores = []\n",
    "        for url in url_iter(dataset_dict, query):\n",
    "            sim_score = model.get_sim_score(dataset_dict, query_words, url)\n",
    "            scores.append((url, sim_score))\n",
    "        \n",
    "        scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "        ranked_doc_list, _ = zip(*scores)\n",
    "        ranked_doc_list = list(ranked_doc_list)\n",
    "\n",
    "        ndcg_sum += NDCG(ranked_doc_list, query_relevance_dict)\n",
    "        alt_ndcg_sum += NDCG(ranked_doc_list, query_relevance_dict, use_alt=True)\n",
    "        precision_sum += average_precision(ranked_doc_list, query_relevance_dict)\n",
    "    \n",
    "    ndcg_sum /= n\n",
    "    alt_ndcg_sum  /= n\n",
    "    precision_sum /= n\n",
    "    return {'NDCG': ndcg_sum,\n",
    "            'Alt_NDCG': alt_ndcg_sum,\n",
    "            'MAP': precision_sum,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec extension model performance on dev data with title and header\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8906751178720381,\n",
       " 'Alt_NDCG': 0.8505309883756115,\n",
       " 'MAP': 0.7915049801282521}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Word2vec extension model performance on dev data with title and header\")\n",
    "run_metrics_word2vec(dev_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Baseline Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading idf...\n",
      "\n",
      "Total Number of Docs is 98998\n",
      "Total Number of Terms is 347071\n"
     ]
    }
   ],
   "source": [
    "from base_classes.id_map import IdMap\n",
    "class tf_idf(object):\n",
    "    def __init__(self, q_weight_scheme=['b', 't', 'n'], doc_weight_scheme=['n', 'n', 'n']):\n",
    "        '''The default weighing scheme is:\n",
    "        q_weight_scheme - \n",
    "                'b': boolean tf\n",
    "                't': weighted by idf (smoothed)\n",
    "                'n': no normalization as the ranking ordering won't be affected\n",
    "        \n",
    "        doc_weight_scheme - \n",
    "                'n': normal tf\n",
    "                'n': no idf (would be already contained with query word for sim score calculation)\n",
    "                'n': none  \n",
    "        '''\n",
    "        self.q_weight_scheme = q_weight_scheme\n",
    "        self.doc_weight_scheme = doc_weight_scheme\n",
    "        \n",
    "        try:\n",
    "            print(\"Loading idf...\\n\")\n",
    "            with open(os.path.join(data_dir, 'docs.dict'), 'rb') as f:\n",
    "                docs = pkl.load(f)\n",
    "            self.total_doc_num = len(docs)\n",
    "            print(\"Total Number of Docs is\", self.total_doc_num)\n",
    "\n",
    "            with open(os.path.join(data_dir, 'terms.dict'), 'rb') as f:\n",
    "                terms = pkl.load(f)\n",
    "            self.total_term_num = len(terms)\n",
    "            print(\"Total Number of Terms is\", self.total_term_num)\n",
    "\n",
    "            with open(os.path.join(data_dir, 'BSBI.dict'), 'rb') as f:\n",
    "                postings_dict, termsID = pkl.load(f)\n",
    "\n",
    "            self.idf = {}\n",
    "            for term_ID in postings_dict:\n",
    "                _, n, _ = postings_dict[term_ID]\n",
    "                self.idf[terms[term_ID]] = math.log10((self.total_doc_num + 1)/(n + 1))\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"doc_dict_file / term_dict_file Not Found!\")\n",
    "    \n",
    "    def get_idf(self, term):\n",
    "        '''return idf value for a term'''\n",
    "        return self.idf.get(term.lower(), math.log10((self.total_doc_num+1)))\n",
    "        \n",
    "    \n",
    "    def get_query_vector(self, query_words):\n",
    "        \n",
    "        query_vec = {}\n",
    "\n",
    "        if self.q_weight_scheme[0] == 'b':\n",
    "            query_vec = Counter(set(query_words))\n",
    "            \n",
    "        if self.q_weight_scheme[1] == 't': #idf\n",
    "            for query_word in query_vec:\n",
    "                idf_value = self.get_idf(query_word)\n",
    "                query_vec[query_word] *= idf_value\n",
    "        \n",
    "        if self.q_weight_scheme[2] is 'n' or None:\n",
    "            pass\n",
    "\n",
    "        return query_vec\n",
    "        \n",
    "    \n",
    "    def get_doc_vector(self, document_words):\n",
    "        '''document words is a list of word lists in the order [[title], [header]]'''\n",
    "        doc_vec = {}\n",
    "        if self.doc_weight_scheme[0] == 'n':\n",
    "            for word_list in document_words:\n",
    "                doc_vec.update(Counter(word_list))\n",
    "        \n",
    "        if self.doc_weight_scheme[1] == 'n':\n",
    "            pass\n",
    "        \n",
    "        if self.doc_weight_scheme[1] == 'n':\n",
    "            pass\n",
    "        \n",
    "        return doc_vec\n",
    "            \n",
    "        \n",
    "        \n",
    "    def get_sim_score(self, query_words, document_words):\n",
    "        \"\"\" Get the similarity score between a document and a query. \n",
    "        Args:\n",
    "            query_words : list of query words where each word is a string\n",
    "            document : list of list of document words where each doc \n",
    "            \n",
    "        Return:\n",
    "            the raw similarity\n",
    "        \"\"\"\n",
    "        query_vec = self.get_query_vector(query_words)\n",
    "        doc_vec = self.get_doc_vector(document_words)\n",
    "        \n",
    "        similarity_score = 0.\n",
    "        for q_word in query_vec:\n",
    "            similarity_score += query_vec[q_word] * doc_vec.get(q_word, 0)\n",
    "            \n",
    "        return similarity_score\n",
    "    \n",
    "tf_idf_baseline = tf_idf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_metrics_baseline(dataset_dict, baseline_model = tf_idf_baseline, content = 'th'):\n",
    "    \"\"\"\n",
    "    Evaluates the baseline on ndcg, ndcg alt, and map\n",
    "    content = 'th' - just include title and header\n",
    "            = 'thb' - run over title, header, and body\n",
    "    \"\"\"\n",
    "    # TODO: shouldnt have to use the featurizer here, need to improve this API\n",
    "    ndcg_sum = 0.0\n",
    "    alt_ndcg_sum = 0.0\n",
    "    precision_sum = 0.0\n",
    "    n = 0\n",
    "    \n",
    "    if content == 'th':\n",
    "        content_list = ['title', 'header'] \n",
    "    elif content == 'thb':\n",
    "        content_list = ['title', 'header', 'body']\n",
    "    else:\n",
    "        raise ValueError('content {} is not valid'.format(content))\n",
    "    \n",
    "    for query in query_iter(dataset_dict):\n",
    "        n += 1\n",
    "        query_relevance_dict = get_relevance_dict(dataset_dict, query)\n",
    "        query_words = get_query_words(dataset_dict, query)\n",
    "        \n",
    "        scores = []\n",
    "        for url in url_iter(dataset_dict, query):\n",
    "            document_words = [get_doc_words(dataset_dict, url, content_type) for content_type in content_list]\n",
    "            sim_score = baseline_model.get_sim_score(query_words, document_words)\n",
    "            scores.append((url, sim_score))\n",
    "        \n",
    "        scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "        ranked_doc_list, _ = zip(*scores)\n",
    "        ranked_doc_list = list(ranked_doc_list)\n",
    "\n",
    "        ndcg_sum += NDCG(ranked_doc_list, query_relevance_dict)\n",
    "        alt_ndcg_sum += NDCG(ranked_doc_list, query_relevance_dict, use_alt=True)\n",
    "        precision_sum += average_precision(ranked_doc_list, query_relevance_dict)\n",
    "    \n",
    "    ndcg_sum /= n\n",
    "    alt_ndcg_sum  /= n\n",
    "    precision_sum /= n\n",
    "    return {'NDCG': ndcg_sum,\n",
    "            'Alt_NDCG': alt_ndcg_sum,\n",
    "            'MAP': precision_sum,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance on training data with title and header only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.859428187699434,\n",
       " 'Alt_NDCG': 0.8090768420250245,\n",
       " 'MAP': 0.7657398318695526}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Baseline performance on training data with title and header only\")\n",
    "run_metrics_baseline(train_dict, content = 'th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance on dev data with title and header only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8602470267115788,\n",
       " 'Alt_NDCG': 0.8057228287185719,\n",
       " 'MAP': 0.7677681543047327}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Baseline performance on dev data with title and header only\")\n",
    "run_metrics_baseline(dev_dict, content = 'th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance on training data with title, header, and body\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8511618664512215,\n",
       " 'Alt_NDCG': 0.7948887145778446,\n",
       " 'MAP': 0.7653206132994661}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Baseline performance on training data with title, header, and body\")\n",
    "run_metrics_baseline(train_dict, content='thb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance on dev data with title, header, and body\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8476474846950123,\n",
       " 'Alt_NDCG': 0.7853309860078931,\n",
       " 'MAP': 0.7671287533830737}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Baseline performance on dev data with title, header, and body\")\n",
    "run_metrics_baseline(dev_dict, content='thb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Glove checkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwords_not_in_glove = {}\n",
    "for query in query_iter(train_dict):\n",
    "    query_words = get_query_words(train_dict, query)\n",
    "    for qw in query_words:\n",
    "        if qw not in glove_lookup:\n",
    "            qwords_not_in_glove[qw] = qwords_not_in_glove.get(qw, 0) + 1\n",
    "print(qwords_not_in_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_CS276_HOME = os.path.join(os.path.join(base_dir_name, os.path.join('data', 'glove.6B')), 'cs276_glove.6B')\n",
    "glove_cs276_lookup = utils.glove2dict(os.path.join(GLOVE_CS276_HOME, 'glove.6B.100d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwords_not_in_cs276_glove = {}\n",
    "for query in query_iter(train_dict):\n",
    "    query_words = get_query_words(train_dict, query)\n",
    "    for qw in query_words:\n",
    "        if qw not in glove_cs276_lookup:\n",
    "            qwords_not_in_cs276_glove[qw] = qwords_not_in_cs276_glove.get(qw, 0) + 1\n",
    "print(qwords_not_in_cs276_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words present\n"
     ]
    }
   ],
   "source": [
    "near_words = ['stanford', 'university', 'location', 'course', 'assignment', 'cs', \\\n",
    "               'student', 'professor', 'recreational', 'gym']\n",
    "not_there = []\n",
    "\n",
    "for n_w in near_words:\n",
    "    if n_w not in glove_lookup:\n",
    "        not_there.append(n_w)\n",
    "        \n",
    "if len(not_there) == 0:\n",
    "    print(\"All words present\")\n",
    "else:\n",
    "    print(not_there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_words_embeddings = {} #word embeddings for words not present in the vocab\n",
    "\n",
    "near_words = ['stanford', 'university', 'location', 'course', 'assignment', 'cs', \\\n",
    "               'student', 'professor', 'recreational', 'gym']\n",
    "\n",
    "#change function name to make_glove_embedding if you want to use this and fit to other api functions\n",
    "def make_glove_embedding_random(words, combine_func=None, glove_dim = 100):\n",
    "    '''This function tries to handle the OOV words by taking a random weighing of the embeddings from the\n",
    "    near_words_words. This handling failed to give improved results over the original make_glove_embedding and makes\n",
    "    the approach very domain specific.'''\n",
    "    \n",
    "    if len(words) == 0:\n",
    "        return np.zeros(glove_dim)\n",
    "    \n",
    "    for word in words:\n",
    "        assert isinstance(word, str), (type(word), word)\n",
    "\n",
    "    global other_words_embeddings\n",
    "    \n",
    "    embedding_list = []\n",
    "    for word in words:\n",
    "        if word in glove_lookup:\n",
    "            embedding_list.append(glove_lookup[word])\n",
    "        elif word in other_words_embeddings:\n",
    "            embedding_list.append(other_words_embeddings[word])\n",
    "        else:\n",
    "            random_numbers = np.random.randint(5, size = 10)\n",
    "            assert np.sum(random_numbers) > 0, \"Random number summing to zero\"\n",
    "            random_numbers = random_numbers/np.sum(random_numbers)\n",
    "            \n",
    "            embedding = np.zeros(glove_dim)\n",
    "            for i in range(len(near_words)):\n",
    "                embedding += random_numbers[i] * np.array(glove_lookup[near_words[i]])\n",
    "            other_words_embeddings[word] = list(embedding)\n",
    "            embedding_list.append(other_words_embeddings[word])\n",
    "            \n",
    "    assert len(embedding_list) == len(words), \"Random embeddings not created\"\n",
    "    \n",
    "    embedding_list = np.array(embedding_list)\n",
    "    if combine_func:\n",
    "        feats = combine_func(embedding_list)\n",
    "    else: # take the elemnetwise mean by default\n",
    "        feats = np.mean(embedding_list, axis=0) \n",
    "    \n",
    "    return feats\n",
    "\n",
    "make_glove_embedding(['aoerc'], combine_func=None, glove_dim = 100)\n",
    "make_glove_embedding(['abjbh'], combine_func=None, glove_dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title on train with embedded OOV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8644623028586048,\n",
       " 'Alt_NDCG': 0.8152507288574898,\n",
       " 'MAP': 0.7760472346853018}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Title on train with embedded OOV\")\n",
    "run_metrics(train_dict, scoring_func=cosine_similarity, content_type='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title on dev with embedded OOV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8588523197194919,\n",
       " 'Alt_NDCG': 0.8080965801311629,\n",
       " 'MAP': 0.7638800121303003}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Title on dev with embedded OOV\")\n",
    "run_metrics(dev_dict, scoring_func=cosine_similarity, content_type='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header on train with embedded OOV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8566425658842325,\n",
       " 'Alt_NDCG': 0.8034638293190356,\n",
       " 'MAP': 0.7669517475808014}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Header on train with embedded OOV\")\n",
    "run_metrics(train_dict, scoring_func=cosine_similarity, content_type='header')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header on dev with embedded OOV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8565573820349158,\n",
       " 'Alt_NDCG': 0.8011692169873779,\n",
       " 'MAP': 0.7684341702630876}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Header on dev with embedded OOV\")\n",
    "run_metrics(dev_dict, scoring_func=cosine_similarity, content_type='header')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th on train with embedded OOV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8675480398731951,\n",
       " 'Alt_NDCG': 0.818663948699515,\n",
       " 'MAP': 0.7777938315587334}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2th on train with embedded OOV\")\n",
    "run_metrics(train_dict, scoring_func=cosine_similarity, content_type='2th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th on dev with embedded OOV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.868774301574093,\n",
       " 'Alt_NDCG': 0.8188404574703219,\n",
       " 'MAP': 0.7784159824323995}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2th on dev with embedded OOV\")\n",
    "run_metrics(dev_dict, scoring_func=cosine_similarity, content_type='2th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body on train with embedded OOV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.8522017338427332,\n",
       " 'Alt_NDCG': 0.7944443819485472,\n",
       " 'MAP': 0.7679846326974642}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"body on train with embedded OOV\")\n",
    "run_metrics(train_dict, scoring_func=cosine_similarity, content_type='body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body on dev with embedded OOV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.864038395716416,\n",
       " 'Alt_NDCG': 0.8037427257593366,\n",
       " 'MAP': 0.791294673335284}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"body on dev with embedded OOV\")\n",
    "run_metrics(dev_dict, scoring_func=cosine_similarity, content_type='body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
