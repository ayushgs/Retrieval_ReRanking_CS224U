{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "from math import log2\n",
    "import utils\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_name = os.getcwd()\n",
    "data_dir_name = \"project_data\"\n",
    "data_dir = os.path.join(base_dir_name, data_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleMap:\n",
    "    \"\"\"\n",
    "    For every unique item entered to the DoubleMap (could be query, url, etc)\n",
    "    assigns a unique integer.\n",
    "    Can only retrieve ids for items entered to the DoubleMap, \n",
    "    and can retrieve items by id!\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.id_to_item = []\n",
    "        self.item_to_id = {}\n",
    "    \n",
    "    def add_item(self, item):\n",
    "        if item not in self.item_to_id:\n",
    "            self.item_to_id[item] = len(self)\n",
    "            self.id_to_item.append(item)\n",
    "            \n",
    "    def get_item(self, ID):\n",
    "        assert ID < len(self.id_to_item)\n",
    "        return self.id_to_item[ID]\n",
    "        \n",
    "    def get_id(self, item):\n",
    "        assert item in self.item_to_id, item\n",
    "        return self.item_to_id[item]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.id_to_item)\n",
    "    \n",
    "# sanity check\n",
    "testMap = DoubleMap()\n",
    "assert len(testMap) == 0\n",
    "testMap.add_item('a')\n",
    "testMap.add_item('b')\n",
    "assert len(testMap) == 2\n",
    "assert testMap.get_id('b') == 1\n",
    "assert testMap.get_item(0) == 'a'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing signal and relevance train files...\n",
      "\n",
      "Signal File\n",
      "749\n",
      "749\n",
      "749\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Relevance File\n",
      "749\n",
      "749\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing signal and relevance train files...\")\n",
    "\n",
    "print(\"\\nSignal File\")\n",
    "query_dict = {} #maps queries to query id (Assuming distinct queries)\n",
    "doc_dict = {}  #maps docs to doc id\n",
    "query_doc_dict = {} #maps query ids to list of doc ids\n",
    "\n",
    "query_id_list = [] #list\n",
    "doc_id_list = []\n",
    "\n",
    "doc_list_for_query = []\n",
    "\n",
    "query_repetitions = {} #dict mapping queries to number of repetitions\n",
    "query_counter = 0\n",
    "doc_repetitions = 0\n",
    "\n",
    "with open(os.path.join(data_dir, \"pa3.signal.train\"), \"r\", encoding='utf8') as f:\n",
    "    last_query_id = 0 \n",
    "    for line in f:\n",
    "        line_list = line.split()\n",
    "        if line_list[0] == 'query:':\n",
    "            query_counter += 1\n",
    "            if query_counter >= 2:\n",
    "                query_doc_dict[last_query_id] = doc_list_for_query\n",
    "                \n",
    "            query = \" \".join(line_list[1:])\n",
    "            \n",
    "            if query_dict.get(query, None) != None:\n",
    "                query_repetitions[query] = query_repetitions.get(query, 0) + 1\n",
    "                query = query + \" _\" + str(query_repetitions[query])\n",
    "            \n",
    "            query_id_list.append(query)\n",
    "            query_dict[query] = len(query_id_list) - 1\n",
    "            \n",
    "            #query_doc_dict[last_query_id] = doc_list_for_query\n",
    "            last_query_id = len(query_id_list) - 1 #update the last query whenever a new query starts\n",
    "            doc_list_for_query = [] #reinitialize the doc list whenever a new query starts\n",
    "        \n",
    "        elif line_list[0] == 'url:':\n",
    "            assert len(line_list) == 2, \"line_list for url has more than 2 entries. Please check!\"\n",
    "            doc = line_list[1]\n",
    "            if doc_dict.get(doc, None) == None:\n",
    "                doc_id_list.append(doc)\n",
    "                doc_id = len(doc_id_list) -1\n",
    "                doc_dict[doc] = doc_id\n",
    "            else:\n",
    "                doc_id = doc_dict[doc]\n",
    "            if doc_id not in doc_list_for_query: \n",
    "                doc_list_for_query.append(doc_id)\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    query_doc_dict[last_query_id] = doc_list_for_query\n",
    "            \n",
    "print(query_counter)\n",
    "print(len(query_dict))\n",
    "print(len(query_doc_dict))\n",
    "    \n",
    "print(\"\\n\" + \"--\"*10 + \"\\n\")\n",
    "\n",
    "import copy\n",
    "query_total_repetitions = copy.deepcopy(query_repetitions)\n",
    "query_doc_relevance = {}\n",
    "doc_relevance_dict = {}\n",
    "query_counter = 0\n",
    "print(\"\\nRelevance File\")\n",
    "with open(os.path.join(data_dir, \"pa3.rel.train\"), \"r\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        line_list = line.split()\n",
    "        if line_list[0] == 'query:':\n",
    "            query_counter += 1\n",
    "            query = \" \".join(line_list[1:])\n",
    "            if query_repetitions.get(query, None) != None:\n",
    "                query_repetition_number = query_total_repetitions[query] - query_repetitions[query]\n",
    "                query_repetitions[query] -= 1\n",
    "                if query_repetition_number != 0:\n",
    "                    query = query + \" _\" + str(query_repetition_number)\n",
    "            \n",
    "            if query_counter >= 2:\n",
    "                assert query_doc_relevance.get(last_query_id, None) == None, \"Query already existed in the relevance dict\"\n",
    "                query_doc_relevance[last_query_id] = doc_relevance_dict\n",
    "            \n",
    "            last_query_id = query_dict[query]\n",
    "            doc_relevance_dict = {}\n",
    "            \n",
    "        elif line_list[0] == \"url:\":\n",
    "            doc = line_list[1]\n",
    "            docID = doc_dict[doc]\n",
    "            \n",
    "            doc_relevance_dict[docID] = float(line_list[-1].strip())\n",
    "    \n",
    "    query_doc_relevance[last_query_id] = doc_relevance_dict\n",
    "\n",
    "print(query_counter)\n",
    "print(len(query_doc_relevance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7490\n"
     ]
    }
   ],
   "source": [
    "#number of unique queries\n",
    "n_queries = len(query_dict)\n",
    "n_unique_queries = len(query_dict)\n",
    "for repeated_query in query_total_repetitions:\n",
    "    n_unique_queries -= query_total_repetitions[repeated_query]\n",
    "\n",
    "total_docs = len(doc_list_for_query) * n_queries\n",
    "print(total_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric - NDCG \n",
    "\n",
    "can also incorporate Precision, MAP, etc. after binary conversion with decay rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCG(ranked_docs, relevance_dict):\n",
    "    '''This function takes an ordered/ranked document list with the ground truth relevance labels from the \n",
    "    relevance_dict and returns a DCG score for the retrieval/ranking.\n",
    "    Input -- \n",
    "        ranked_docs = list of doc IDs ordered by rank. First element in the list is the highest ranked\n",
    "        relevance_dict = dict with keys as the doc_IDs and relevance score as the element\n",
    "    Output -- \n",
    "        DCG [float]'''\n",
    "    \n",
    "    discount_factor = []\n",
    "    relevance_scores = []\n",
    "    for i, doc in enumerate(ranked_docs):\n",
    "        rank = i+1\n",
    "        if rank == 1:\n",
    "            discount_factor.append(1)\n",
    "        else:\n",
    "            discount_factor.append(log2(rank))\n",
    "        relevance_scores.append(relevance_dict[doc])\n",
    "    \n",
    "    return sum(np.array(relevance_scores)/np.array(discount_factor))\n",
    "            \n",
    "def NDCG(ranked_docs, relevance_dict):\n",
    "    '''This function takes an ordered/ranked document list with the ground truth relevance labels from the \n",
    "    relevance_dict and returns a NDCG score for the ranking. \n",
    "    Input -- \n",
    "        ranked_docs = list of doc IDs ordered by rank. First element in the list is the highest ranked\n",
    "        relevance_dict = dict with keys as the doc_IDs and relevance score as the element\n",
    "    Output -- \n",
    "        NDCG [float]'''\n",
    "  \n",
    "    ideal_ordering, _ = zip(*sorted(relevance_dict.items(), key = lambda x: (-x[1])))\n",
    "    ideal_ordering = list(ideal_ordering)\n",
    "\n",
    "    DCG_oracle = DCG(ideal_ordering, relevance_dict)\n",
    "    DCG_case = DCG(ranked_docs, relevance_dict)\n",
    "    \n",
    "    assert len(ideal_ordering) == len(ranked_docs), (ranked_docs, ideal_ordering, relevance_dict)\n",
    "    assert DCG_oracle >= DCG_case, (DCG_oracle, DCG_case, ideal_ordering, ranked_docs, relevance_dict)\n",
    "    \n",
    "    #return 1 if DCG_ideal is 0 (happens when all the retrieved docs are rated 0)\n",
    "    if DCG_oracle == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return DCG_case/DCG_oracle\n",
    "\n",
    "#sanity check\n",
    "ranked_docs = [0,1,2,3,4]\n",
    "relevance_dict = {0: 2, 1: 3, 2: 0, 3: 0, 4: 1}\n",
    "DCG_score = 2 + 3/log2(2) + 1/log2(5)\n",
    "Ideal_score = 3 + 2/log2(2) + 1/log2(3)\n",
    "NDCG_score = DCG_score/Ideal_score\n",
    "assert DCG(ranked_docs, relevance_dict) == DCG_score, \"DCG error\"\n",
    "assert NDCG(ranked_docs, relevance_dict) == NDCG_score, \"NDCG error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random ordering accuracy\n",
    "\n",
    "For every query, arrange the docs in random order and check the NDCG value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600.0568208298147\n",
      "749\n",
      "0.8011439530438114\n"
     ]
    }
   ],
   "source": [
    "#randomly shuffles the docs\n",
    "ndcg_sum = 0.0\n",
    "for queryID, doc_list in query_doc_dict.items():\n",
    "    np.random.shuffle(doc_list)\n",
    "    #print(query_id_list[queryID], doc_list)\n",
    "    ndcg_sum += NDCG(doc_list, query_doc_relevance[queryID])\n",
    "print(ndcg_sum)\n",
    "print(len(query_id_list))\n",
    "print(ndcg_sum/len(query_id_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing query and document embeddings\n",
    "\n",
    "Document embeddings are obtained from the given title or header information without any weight normalization. Loop through the files and collect doc words by looking in the title and header (one idea can be to give more weight to title than to header). Lookup for each word in the glove embedding. Choose and fix a random combination of word if a word in query does not exist (maybe a combination from the words university and around because the corpus relates to stanford). Ignore otherwise. Finally, find cosine similarity and rank and compute NDCG score. \n",
    "\n",
    "#### Other ideas:\n",
    "1. Treat upper case and start of line word different than end of line word, etc\n",
    "2. Can add word correction, etc\n",
    "3. How scraping documents and adding more words to document effect performance\n",
    "4. Modeling item-item dependency by seq2slate architecture\n",
    "5. Creating embedding for words in the query but not in the embedding vocab as a distinct combination for \n",
    "6. Training word2vec on this and then trying different ideas with the center and context matrices obtained\n",
    "7. DESM type ideas with the embeddings of words in the document weighted by the similarity of words (W_out * q_emb)\n",
    "8. Treating re-ranking task as an NLI task where document entails query\n",
    "9. regressing score for each query-doc pair using nlp inspired regression by predicting score through RNN for instance\n",
    "10. experimenting with listwise and pairwise approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing doc number -  50\n",
      "% complete - 0.67 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  100\n",
      "% complete - 1.34 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  150\n",
      "% complete - 2.00 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  200\n",
      "% complete - 2.67 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  250\n",
      "% complete - 3.34 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  300\n",
      "% complete - 4.01 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  350\n",
      "% complete - 4.67 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  400\n",
      "% complete - 5.34 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  450\n",
      "% complete - 6.01 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  500\n",
      "% complete - 6.68 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  550\n",
      "% complete - 7.34 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  600\n",
      "% complete - 8.01 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  650\n",
      "% complete - 8.68 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  700\n",
      "% complete - 9.35 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  750\n",
      "% complete - 10.01 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  800\n",
      "% complete - 10.68 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  850\n",
      "% complete - 11.35 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  900\n",
      "% complete - 12.02 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  950\n",
      "% complete - 12.68 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1000\n",
      "% complete - 13.35 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1050\n",
      "% complete - 14.02 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1100\n",
      "% complete - 14.69 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1150\n",
      "% complete - 15.35 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1200\n",
      "% complete - 16.02 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1250\n",
      "% complete - 16.69 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1300\n",
      "% complete - 17.36 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1350\n",
      "% complete - 18.02 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1400\n",
      "% complete - 18.69 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1450\n",
      "% complete - 19.36 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1500\n",
      "% complete - 20.03 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1550\n",
      "% complete - 20.69 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1600\n",
      "% complete - 21.36 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1650\n",
      "% complete - 22.03 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1700\n",
      "% complete - 22.70 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1750\n",
      "% complete - 23.36 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1800\n",
      "% complete - 24.03 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1850\n",
      "% complete - 24.70 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1900\n",
      "% complete - 25.37 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  1950\n",
      "% complete - 26.03 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2000\n",
      "% complete - 26.70 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2050\n",
      "% complete - 27.37 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2100\n",
      "% complete - 28.04 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2150\n",
      "% complete - 28.70 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2200\n",
      "% complete - 29.37 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2250\n",
      "% complete - 30.04 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2300\n",
      "% complete - 30.71 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2350\n",
      "% complete - 31.38 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2400\n",
      "% complete - 32.04 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2450\n",
      "% complete - 32.71 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2500\n",
      "% complete - 33.38 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2550\n",
      "% complete - 34.05 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2600\n",
      "% complete - 34.71 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2650\n",
      "% complete - 35.38 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2700\n",
      "% complete - 36.05 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2750\n",
      "% complete - 36.72 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2800\n",
      "% complete - 37.38 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2850\n",
      "% complete - 38.05 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2900\n",
      "% complete - 38.72 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  2950\n",
      "% complete - 39.39 %\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing doc number -  3000\n",
      "% complete - 40.05 %\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#building word corpus for each document\n",
    "doc_counter = 0\n",
    "last_doc_content = []\n",
    "docId_to_content = {} #dict maps from doc id to the contents in the doc. The content is saved as a list of vocab_ids\n",
    "queryID_to_content = {}\n",
    "\n",
    "#vocab includes words from both, query and docs\n",
    "vocab_dict = {} #mapping from vocab term to id \n",
    "vocab_id_list = [] #list where id maps to the vocab term (0 indexed)\n",
    "vocab_frequency = {} #number of times each vocab term appears in the vocab of documents (included query words)\n",
    "\n",
    "with open(os.path.join(data_dir, \"pa3.signal.train\"), \"r\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        line_list = line.split()\n",
    "        \n",
    "        if line_list[0] == 'query:':\n",
    "            query = \" \".join(line_list[1:])\n",
    "            queryID = query_dict[query]\n",
    "            word_id_list = []\n",
    "            for word in line_list[1:]:\n",
    "                word = word.strip().lower()\n",
    "                vocab_frequency[word] = vocab_frequency.get(word, 0) + 1\n",
    "\n",
    "                if vocab_dict.get(word, None) == None:\n",
    "                    vocab_id_list.append(word)\n",
    "                    vocab_dict[word] = len(vocab_id_list) - 1\n",
    "\n",
    "                word_id = vocab_dict[word]\n",
    "                word_id_list.append(word_id)\n",
    "            \n",
    "            queryID_to_content[queryID] = word_id_list \n",
    "            \n",
    "        elif line_list[0] == 'url:':\n",
    "            doc_counter += 1\n",
    "            \n",
    "            #printing processing\n",
    "            if doc_counter % 50 == 0:\n",
    "                print(\"Processing doc number - \", doc_counter)\n",
    "                print(\"% complete - {:.2f} %\".format((doc_counter/total_docs)*100))\n",
    "                print(\"\\n\" + \"--\"*10 + \"\\n\")\n",
    "                \n",
    "            doc = line_list[1]\n",
    "            docID = doc_dict[doc]\n",
    "\n",
    "            if doc_counter >= 2:\n",
    "                docId_to_content[last_docID] = last_doc_content\n",
    "                \n",
    "            last_doc_content = []\n",
    "            last_docID = docID\n",
    "                \n",
    "        elif line_list[0] == 'title:':\n",
    "            for word in line_list[1:]:\n",
    "                word = word.strip().lower()\n",
    "                vocab_frequency[word] = vocab_frequency.get(word, 0) + 1\n",
    "\n",
    "                if vocab_dict.get(word, None) == None:\n",
    "                    vocab_id_list.append(word)\n",
    "                    vocab_dict[word] = len(vocab_id_list) - 1\n",
    "\n",
    "                word_id = vocab_dict[word]\n",
    "                last_doc_content += [word_id, word_id] #adding each word twice for title\n",
    "                \n",
    "        elif line_list[0] == 'header:':\n",
    "            for word in line_list[1:]:\n",
    "                word = word.strip().lower()\n",
    "                vocab_frequency[word] = vocab_frequency.get(word, 0) + 1\n",
    "\n",
    "                if vocab_dict.get(word, None) == None:\n",
    "                    vocab_id_list.append(word)\n",
    "                    vocab_dict[word] = len(vocab_id_list) - 1\n",
    "\n",
    "                word_id = vocab_dict[word]\n",
    "                last_doc_content += [word_id] #adding each word twice for title\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    docId_to_content[last_docID] = last_doc_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''having generated query content and doc content, lets try ranking by cosine similarity between query and document \n",
    "embedding\n",
    "'''\n",
    "#iteration 1: ignore words not there in the embedding\n",
    "\n",
    "#lookup function\n",
    "GLOVE_HOME = os.path.join('data', 'glove.6B')\n",
    "glove_lookup = utils.glove2dict(os.path.join(GLOVE_HOME, 'glove.6B.50d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the document embedding\n",
    "def doc_embedding(docID):\n",
    "    '''#Ignores words not in the vocab\n",
    "    Input: docID\n",
    "    Output: doc embedding'''\n",
    "    \n",
    "    allvecs = np.array([glove_lookup[vocab_id_list[wordID]] for wordID in docId_to_content[docID] \\\n",
    "                        if vocab_id_list[wordID] in glove_lookup]) \n",
    "    \n",
    "    if len(allvecs) == 0:\n",
    "        dim = len(next(iter(glove_lookup.values())))\n",
    "        feats = np.zeros(dim)    \n",
    "    else:       \n",
    "        feats = np.mean(allvecs, axis=0) \n",
    "    \n",
    "    return feats\n",
    "\n",
    "#function to find the query embedding\n",
    "def query_embedding(queryID):\n",
    "    '''#Ignores words not in the vocab\n",
    "    Input: queryID\n",
    "    Output: query embedding'''\n",
    "    \n",
    "    allvecs = np.array([glove_lookup[vocab_id_list[wordID]] for wordID in queryID_to_content[queryID] \\\n",
    "                        if vocab_id_list[wordID] in glove_lookup]) \n",
    "\n",
    "    if len(allvecs) == 0:\n",
    "        dim = len(next(iter(glove_lookup.values())))\n",
    "        feats = np.zeros(dim)    \n",
    "    else:       \n",
    "        feats = np.mean(allvecs, axis=0) \n",
    "    \n",
    "    return feats\n",
    "\n",
    "def cosine_similarity(doc_embedding, query_embedding):\n",
    "    norm = np.linalg.norm(doc_embedding)\n",
    "    if norm > 0:\n",
    "        doc_embedding /= norm\n",
    "    return np.dot(doc_embedding, query_embedding)\n",
    "\n",
    "#sample print\n",
    "#print(doc_embedding(0))\n",
    "#print(query_embedding(0))\n",
    "\n",
    "\n",
    "#iterate over each query and list of documents and check results\n",
    "ndcg_sum = 0.0\n",
    "for queryID, doc_list in query_doc_dict.items():\n",
    "    #doc_list is list of doc_ids for the query given by query_id\n",
    "    query_relevance_dict = query_doc_relevance[queryID]\n",
    "    \n",
    "    query = query_id_list[queryID]\n",
    "    if query.split()[-1][0] == '_':\n",
    "        query = query.split()[:-1]\n",
    "        query = \" \".join(query)\n",
    "        queryID = query_dict[query]\n",
    "    \n",
    "    query_emb = query_embedding(queryID)\n",
    "    scores = [(docID, cosine_similarity(doc_embedding(docID), query_emb)) for docID in doc_list]\n",
    "    scores = sorted(scores, key = lambda x: -x[1])\n",
    "    ranked_doc_list, _ = zip(*scores)\n",
    "    ranked_doc_list = list(ranked_doc_list)\n",
    "    ndcg_sum += NDCG(ranked_doc_list, query_relevance_dict)\n",
    "\n",
    "print(ndcg_sum)\n",
    "print(len(query_id_list))\n",
    "print(ndcg_sum/len(query_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
